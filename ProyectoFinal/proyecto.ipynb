{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num - the predicted attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "297  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  num - the predicted attribute  \n",
       "0      3.0  0.0  6.0                              0  \n",
       "1      2.0  3.0  3.0                              2  \n",
       "2      2.0  2.0  7.0                              1  \n",
       "3      3.0  0.0  3.0                              0  \n",
       "4      1.0  0.0  3.0                              0  \n",
       "..     ...  ...  ...                            ...  \n",
       "297    2.0  0.0  7.0                              1  \n",
       "298    2.0  0.0  7.0                              1  \n",
       "299    2.0  2.0  7.0                              2  \n",
       "300    2.0  1.0  7.0                              3  \n",
       "301    2.0  1.0  3.0                              1  \n",
       "\n",
       "[297 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [\n",
    "    \"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\n",
    "    \"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\n",
    "    \"num - the predicted attribute\"\n",
    "]\n",
    "\n",
    "data = pd.read_csv(\"processed.cleveland.csv\", header=None, names = headers)\n",
    "# Eliminamos las filas que contienen datos malos o desconocidos\n",
    "data = data[ (data[\"ca\"] != '?') & (data[\"thal\"] != '?')]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar los inputs del output\n",
    "X = data.iloc[0:,:13]\n",
    "\n",
    "# Como son valores del 0 al 4 convertimos la data para tener mejores resultados\n",
    "d = data.iloc[0:,13]\n",
    "\n",
    "y = []\n",
    "for i in d.values:\n",
    "    aux = [0 for _ in range(5)]\n",
    "    aux[i] = 1\n",
    "    y.append(aux)\n",
    "y = np.array(y)\n",
    "\n",
    "# Obetener datos de entrenamiento y datos de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, random_state=1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion sin preprocesar la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38666666666666666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3466666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20,20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.1,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.09,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='relu',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49333333333333335"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5066666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.1,\n",
    "    max_iter=3000).fit(X.values, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion con procesamiento escalando los datos entre 0 y 1 dividiendo entre el maximo de cada campo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_scaler = preprocessing.MaxAbsScaler()\n",
    "x_scaled = max_scaler.fit_transform(X.values)\n",
    "Xmax = pd.DataFrame(x_scaled)\n",
    "\n",
    "# Obetener datos de entrenamiento y datos de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xmax, y, random_state=1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20,20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.1,\n",
    "    max_iter=3000).fit(Xmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/USB/redesNeuronales/env/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.0001,\n",
    "    momentum = 0.1,\n",
    "    max_iter=3000).fit(Xmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4266666666666667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='tanh',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.1,\n",
    "    max_iter=3000).fit(Xmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.1,\n",
    "    max_iter=3000).fit(Xmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/USB/redesNeuronales/env/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.1,\n",
    "    max_iter=3000).fit(Xmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion con procesamiento escalando los datos entre 0 y 1 usando la tecnica del MinMax de cada campo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X.values)\n",
    "Xminmax = pd.DataFrame(x_scaled)\n",
    "\n",
    "# Obetener datos de entrenamiento y datos de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xminmax, y, random_state=1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5066666666666667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xminmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20,20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xminmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20,20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.001,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xminmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20,20),\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.1,\n",
    "    max_iter=3000).fit(Xminmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/USB/redesNeuronales/env/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20,20),\n",
    "    activation='tanh',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xminmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20,20),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xminmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/USB/redesNeuronales/env/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(20,20),\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.01,\n",
    "    momentum = 0.9,\n",
    "    max_iter=3000).fit(Xminmax, y)\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit19b03d1776a141f8a54345732b0d5224"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
