{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "from random import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clases para el Adaline y Capa que contiene varias neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "\n",
    "    def __init__(self, n_entradas, bias=None, alfa=0.1):\n",
    "        self.pesos_sinapticos = np.random.uniform(\n",
    "            low=-0.05, high=0.05, size=(n_entradas,))\n",
    "        self.n_entradas = n_entradas\n",
    "        self.bias = bias if bias else uniform(0,0.1)\n",
    "        self.alfa = alfa\n",
    "\n",
    "    def calcular(self, estimulo):\n",
    "        y = np.dot(self.pesos_sinapticos, estimulo)\n",
    "        y += self.bias\n",
    "        self.y = self.lineal(y)\n",
    "        return self.y\n",
    "\n",
    "    def entrenar_estocastico(self, estimulo, resultado_esperado):\n",
    "        \"\"\"\n",
    "            LMS Estocastico\n",
    "        \"\"\"\n",
    "        self.calcular(estimulo)\n",
    "        error = (resultado_esperado - self.y)\n",
    "        delta = self.alfa * error * estimulo\n",
    "        \n",
    "        # Actualizacion\n",
    "        self.pesos_sinapticos = self.pesos_sinapticos + delta\n",
    "        self.bias = self.bias + error * self.alfa\n",
    "        return self.pesos_sinapticos\n",
    "\n",
    "    def entrenar_batch(self, estimulos, resultados_esperados):\n",
    "        \"\"\"\n",
    "            LMS Batch\n",
    "        \"\"\"\n",
    "        delta = np.zeros(self.n_entradas)\n",
    "        for estimulo, respuesta in zip(estimulos, resultados_esperados):\n",
    "            self.calcular(estimulo)\n",
    "            error = (respuesta - self.y)\n",
    "            delta += error * estimulo\n",
    "            self.bias += error * self.alfa\n",
    "        self.pesos_sinapticos = self.pesos_sinapticos + self.alfa * delta\n",
    "\n",
    "    # Por seguir con el algoritmo\n",
    "    def lineal(self, a):\n",
    "        \"\"\"\n",
    "            Funcion de transferencia lineal\n",
    "        \"\"\"\n",
    "        return a\n",
    "\n",
    "    def describir(self):\n",
    "        print(\"PESOS SINAPTICOS: \", self.pesos_sinapticos)\n",
    "        print(\"RESPUESTA: \", self.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capa:\n",
    "\n",
    "    def __init__(self, n_adaline, n_entradas, alfa=0.1):\n",
    "        self.n_adaline = n_adaline\n",
    "        self.n_entradas = n_entradas\n",
    "        self.adalines = [Adaline(n_entradas, alfa=alfa)\n",
    "                             for i in range(n_adaline)]\n",
    "\n",
    "    def entrenar(self, entrada, respuesta):\n",
    "        \"\"\"\n",
    "            Entrenamiento estocastico de las neuronas\n",
    "        \"\"\"\n",
    "        for i in range(self.n_adaline):\n",
    "            if respuesta == i:\n",
    "                self.adalines[i].entrenar_estocastico(entrada, 1)\n",
    "            else:\n",
    "                self.adalines[i].entrenar_estocastico(entrada, 0)\n",
    "\n",
    "    def calcular(self, estimulo):\n",
    "        \"\"\"\n",
    "            Calcular el resultado dado un estimulo a las neuronas\n",
    "        \"\"\"\n",
    "        respuesta = []\n",
    "        for i in range(self.n_adaline):\n",
    "            respuesta.append(self.adalines[i].calcular(estimulo))\n",
    "\n",
    "        return respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dos funciones utiles para entrenar una capa y para verificar esa misma capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def entrenar(capa, epocas=1):\n",
    "    \"\"\"\n",
    "    Entrenar las neuronas de una capa\n",
    "    \"\"\"\n",
    "    with open('../mnist_train.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',',\n",
    "                                quoting=csv.QUOTE_NONNUMERIC)\n",
    "        start = time.time()\n",
    "        leido = 0\n",
    "        for _ in range(epocas):\n",
    "            leido = 0\n",
    "            for row in csv_reader:\n",
    "                # Dividimos los datos por 255 para tenerlos \n",
    "                # en un rango entre 0 y 1\n",
    "                datos = np.array(row[1:]) / 255\n",
    "                capa.entrenar(datos, row[0])\n",
    "                leido += 1\n",
    "                \n",
    "            # Devolvemos el apuntador del archivo al inicio\n",
    "            csv_file.seek(0)\n",
    "        print(f\"Tiempo: {time.time() - start}seg\")\n",
    "        print(f\"No de datos usados para el entrenamiento: {leido}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar(capa):\n",
    "    \"\"\"\n",
    "    Verificar si las neuronas de una capa dada estan entrenadas\n",
    "    \"\"\"\n",
    "    with open('../mnist_test.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',',\n",
    "                                quoting=csv.QUOTE_NONNUMERIC)\n",
    "        line_count = 0\n",
    "        resultados_buenos = 0\n",
    "        resultados_malos = 0\n",
    "        for row in csv_reader:\n",
    "            resultado = row[0]\n",
    "            datos = np.array(row[1:])\n",
    "            res = capa.calcular(datos)\n",
    "            rep = [0,res[0]]\n",
    "            for i, j in enumerate(res):\n",
    "                if j > rep[1] :\n",
    "                    rep[0] = i\n",
    "                    rep[1] = j\n",
    "\n",
    "            if rep[0] == resultado:\n",
    "                resultados_buenos += 1\n",
    "            else:\n",
    "                resultados_malos += 1\n",
    "            line_count += 1\n",
    "\n",
    "        \n",
    "        print(f\"Datos leido: {line_count}\")\n",
    "        print(\n",
    "            f\"Porcentaje de resultados buenos: {resultados_buenos / line_count * 100}%\")\n",
    "        print(\n",
    "            f\"Porcentaje de resultados malos: {resultados_malos / line_count * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos los entrenamientos con las siguientes tasas de aprendizaje:\n",
    "* 0.1\n",
    "* 0.01\n",
    "* 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando etha 0.1 con 10 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Capa(10,784,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 274.76490235328674seg\n",
      "No de datos usados para el entrenamiento: 60000\n"
     ]
    }
   ],
   "source": [
    "entrenar(c,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos leido: 10000\n",
      "Porcentaje de resultados buenos: 9.8%\n",
      "Porcentaje de resultados malos: 90.2%\n"
     ]
    }
   ],
   "source": [
    "verificar(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando etha 0.01 con 10 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Capa(10,784,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 267.24732303619385seg\n",
      "No de datos usados para el entrenamiento: 60000\n"
     ]
    }
   ],
   "source": [
    "entrenar(c1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos leido: 10000\n",
      "Porcentaje de resultados buenos: 59.419999999999995%\n",
      "Porcentaje de resultados malos: 40.58%\n"
     ]
    }
   ],
   "source": [
    "verificar(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando etha 0.001 con 10 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = Capa(10,784,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 292.37622570991516seg\n",
      "No de datos usados para el entrenamiento: 60000\n"
     ]
    }
   ],
   "source": [
    "entrenar(c2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos leido: 10000\n",
      "Porcentaje de resultados buenos: 74.96000000000001%\n",
      "Porcentaje de resultados malos: 25.040000000000003%\n"
     ]
    }
   ],
   "source": [
    "verificar(c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra usando etha 0.0001 con 10 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = Capa(10,784,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 295.4783835411072seg\n",
      "No de datos usados para el entrenamiento: 60000\n"
     ]
    }
   ],
   "source": [
    "entrenar(c3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos leido: 10000\n",
      "Porcentaje de resultados buenos: 80.89%\n",
      "Porcentaje de resultados malos: 19.11%\n"
     ]
    }
   ],
   "source": [
    "verificar(c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaciones con el perceptron\n",
    "\n",
    "![](./resultado-perceptron.png)\n",
    "\n",
    "Con lo que nos queda:\n",
    "\n",
    "| Neurona | 0.1 | 0.01 | 0.001 |\n",
    "| --- | --- | --- | --- | \n",
    "| Perceptron | 75.18% | 81.42% | 81.02% |\n",
    "| Adaline | 9.8% | 59.41% | 74.96% |\n",
    "\n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "Al parecer si ejecutamos la Capa de Adaline con Etha = 0.1 es una muy mala opcion \n",
    "Ahora, si vamos bajando esa tasa de aprendizaje vamos obteniendo mejores resultados\n",
    "al final el mejor resultado fue con 0.0001 dando un porcentaje de resultados buenos \n",
    "de mas del 80%, sin embargo, con este valor no fue probado el perceptron.\n",
    "\n",
    "Tendriamos que volver a ejecutar todos los valores de etha con mas epocas para \n",
    "tener mas informacion del comportamiento con esta neurona y con los datos de entrenamiento\n",
    "sobre los que estamos trabajando."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
